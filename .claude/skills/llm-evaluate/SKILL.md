---
name: llm-evaluate
description: Evaluate LLM models for cost/performance ratio. Fetches current pricing and recommends optimal model for your use case. Use during project init or when optimizing costs.
disable-model-invocation: true
allowed-tools: Read, WebFetch, WebSearch, AskUserQuestion
argument-hint: [use-case]
---

# LLM Model Evaluation

Evaluiert LLM-Modelle basierend auf aktuellem Preis/Leistungs-VerhÃ¤ltnis.

---

## Wann nutzen?

- WÃ¤hrend `/init-project` bei der KomplexitÃ¤tsbewertung
- Bei Kosten-Optimierung bestehender Projekte
- Wenn neue Modelle erscheinen (regelmÃ¤ÃŸig checken)
- Vor grÃ¶ÃŸeren Production-Deployments

---

## Step 1: Use Case verstehen

Falls kein Argument Ã¼bergeben, frage:

```
Was ist dein Use Case?

Beispiele:
â€¢ "Chat-Bot fÃ¼r Kundenservice" (High-Volume, schnelle Antworten)
â€¢ "Dokumenten-Analyse" (Langer Context, Reasoning)
â€¢ "Code-Generierung" (PrÃ¤zision wichtig)
â€¢ "GDPR-konforme EU-App" (Compliance)
â€¢ "Budget-Projekt" (Kosten minimieren)
```

---

## Step 2: Aktuelle Preise holen

**WICHTIG:** Preise Ã¤ndern sich hÃ¤ufig. Hole aktuelle Daten.

### 2.1 Web Search fÃ¼r aktuelle Preise

Suche nach aktuellen Preisen mit WebSearch:

```
Query: "[Provider] API pricing 2026"
```

FÃ¼r jeden Provider:
- Anthropic Claude pricing
- OpenAI GPT pricing
- Google Gemini pricing
- DeepSeek pricing
- xAI Grok pricing
- Mistral pricing

### 2.2 Pricing Endpoints (falls verfÃ¼gbar)

Einige Provider haben Ã¶ffentliche Pricing-Pages:

| Provider | Pricing URL |
|----------|-------------|
| Anthropic | https://www.anthropic.com/pricing |
| OpenAI | https://openai.com/api/pricing |
| Google | https://ai.google.dev/pricing |
| DeepSeek | https://platform.deepseek.com/api-docs/pricing |
| Mistral | https://mistral.ai/technology/#pricing |
| xAI | https://x.ai/api |

### 2.3 Fallback: Cached Reference

Falls Web-Fetch fehlschlÃ¤gt, nutze `.claude/reference/llm-configuration.md` als Fallback (aber weise auf mÃ¶glicherweise veraltete Daten hin).

---

## Step 3: Modelle bewerten

### 3.1 Bewertungskriterien

| Kriterium | Gewichtung | Beschreibung |
|-----------|------------|--------------|
| **Kosten** | 30% | Input + Output Tokens |
| **QualitÃ¤t** | 30% | Benchmark-Scores, Erfahrungswerte |
| **Latenz** | 20% | Time to first token, Throughput |
| **Context** | 10% | Max Context Window |
| **Features** | 10% | Vision, Tools, Streaming |

### 3.2 Use Case Mapping

| Use Case | Wichtig | Unwichtig |
|----------|---------|-----------|
| **Chat-Bot** | Latenz, Kosten | Context |
| **Dokument-Analyse** | Context, QualitÃ¤t | Latenz |
| **Code-Gen** | QualitÃ¤t | Kosten |
| **High-Volume** | Kosten, Latenz | QualitÃ¤t |
| **GDPR** | Compliance | Kosten |

---

## Step 4: Empfehlung ausgeben

### 4.1 Empfehlungs-Template

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM EVALUATION - [Use Case]                                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  ğŸ“… Preise Stand: [Datum der Abfrage]                                       â”‚
â”‚                                                                             â”‚
â”‚  TOP 3 EMPFEHLUNGEN:                                                        â”‚
â”‚                                                                             â”‚
â”‚  ğŸ¥‡ #1: [Modell]                                                            â”‚
â”‚      Provider: [Provider]                                                   â”‚
â”‚      Input:    $[X]/1M tokens                                               â”‚
â”‚      Output:   $[X]/1M tokens                                               â”‚
â”‚      Context:  [X]K                                                         â”‚
â”‚      Score:    [X]/100 (basierend auf Use Case)                             â”‚
â”‚      Warum:    [BegrÃ¼ndung]                                                 â”‚
â”‚                                                                             â”‚
â”‚  ğŸ¥ˆ #2: [Modell]                                                            â”‚
â”‚      ...                                                                    â”‚
â”‚                                                                             â”‚
â”‚  ğŸ¥‰ #3: [Modell]                                                            â”‚
â”‚      ...                                                                    â”‚
â”‚                                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  KOSTEN-SCHÃ„TZUNG (bei 1M Requests/Monat, 1000 Tokens avg):                â”‚
â”‚                                                                             â”‚
â”‚  Modell #1: ~$[X]/Monat                                                     â”‚
â”‚  Modell #2: ~$[X]/Monat                                                     â”‚
â”‚  Modell #3: ~$[X]/Monat                                                     â”‚
â”‚                                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  FALLBACK-STRATEGIE:                                                        â”‚
â”‚                                                                             â”‚
â”‚  Primary:  [Modell #1]                                                      â”‚
â”‚  Fallback: [Modell #2]                                                      â”‚
â”‚  Budget:   [Modell #3]                                                      â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 Portkey Config generieren

Falls gewÃ¼nscht, generiere die Portkey-Konfiguration:

```typescript
// Empfohlene Portkey Konfiguration fÃ¼r [Use Case]
const config = {
  strategy: {
    mode: 'fallback',
  },
  targets: [
    { provider: '[primary]', model: '[model]' },
    { provider: '[fallback]', model: '[model]' },
  ],
  cache: {
    mode: 'semantic',
    ttl: 3600,
  },
};
```

---

## Step 5: Dokumentation aktualisieren

Falls signifikante PreisÃ¤nderungen gefunden wurden:

1. Weise den User darauf hin
2. Frage ob `.claude/reference/llm-configuration.md` aktualisiert werden soll
3. Bei "Ja": Update die Preistabellen

---

## Automatische Intervall-Checks

### Weekly Reminder

Dieser Skill sollte regelmÃ¤ÃŸig genutzt werden:

```
Empfehlung: FÃ¼hre /llm-evaluate monatlich aus um:
- Neue Modelle zu entdecken
- PreisÃ¤nderungen zu berÃ¼cksichtigen
- Kosten-Optimierung zu prÃ¼fen
```

### Bei Projekt-Init

WÃ¤hrend `/init-project` wird dieser Skill automatisch bei der KomplexitÃ¤tsbewertung (Step 0.2) aufgerufen um das optimale Modell fÃ¼r den Use Case zu empfehlen.

---

## Modell-Datenbank (Referenz)

### Anthropic

| Modell | Input/1M | Output/1M | Context | StÃ¤rken |
|--------|----------|-----------|---------|---------|
| Claude Opus 4.5 | $15 | $75 | 200K | Best reasoning |
| Claude Sonnet 4 | $3 | $15 | 200K | Best coding |
| Claude Haiku 3.5 | $0.25 | $1.25 | 200K | Fast, cheap |

### OpenAI

| Modell | Input/1M | Output/1M | Context | StÃ¤rken |
|--------|----------|-----------|---------|---------|
| GPT-4o | $5 | $15 | 128K | Multimodal |
| GPT-4o-mini | $0.15 | $0.60 | 128K | Budget GPT-4 |
| o1 | $15 | $60 | 200K | Deep reasoning |

### Google

| Modell | Input/1M | Output/1M | Context | StÃ¤rken |
|--------|----------|-----------|---------|---------|
| Gemini 2.0 Pro | $7 | $21 | 1M | Long context |
| Gemini 2.0 Flash | $0.10 | $0.40 | 1M | Fast, cheap |
| Gemini Flash 8B | $0.04 | $0.15 | 1M | Ultra cheap |

### DeepSeek

| Modell | Input/1M | Output/1M | Context | StÃ¤rken |
|--------|----------|-----------|---------|---------|
| DeepSeek V3 | $0.27 | $1.10 | 64K | Open-weight |
| DeepSeek R1 | $0.55 | $2.19 | 64K | Reasoning |

### xAI

| Modell | Input/1M | Output/1M | Context | StÃ¤rken |
|--------|----------|-----------|---------|---------|
| Grok 2 | $2 | $10 | 128K | Realtime data |
| Grok 2 Vision | $2 | $10 | 32K | Image understanding |

### Mistral

| Modell | Input/1M | Output/1M | Context | StÃ¤rken |
|--------|----------|-----------|---------|---------|
| Mistral Large | $2 | $6 | 128K | EU-hosted |
| Codestral | $0.30 | $0.90 | 256K | Code |
| Mistral Small | $0.20 | $0.60 | 128K | Budget |

---

## Beispiel-AusfÃ¼hrung

```
User: /llm-evaluate Chat-Bot fÃ¼r Kundenservice

Claude:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM EVALUATION - Customer Service Chat Bot                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  ğŸ“… Preise Stand: Januar 2026                                               â”‚
â”‚                                                                             â”‚
â”‚  TOP 3 EMPFEHLUNGEN:                                                        â”‚
â”‚                                                                             â”‚
â”‚  ğŸ¥‡ #1: Claude Haiku 3.5                                                    â”‚
â”‚      Provider: Anthropic                                                    â”‚
â”‚      Input:    $0.25/1M tokens                                              â”‚
â”‚      Output:   $1.25/1M tokens                                              â”‚
â”‚      Context:  200K                                                         â”‚
â”‚      Score:    92/100                                                       â”‚
â”‚      Warum:    Schnell, gÃ¼nstig, gute QualitÃ¤t fÃ¼r Chat                     â”‚
â”‚                                                                             â”‚
â”‚  ğŸ¥ˆ #2: Gemini 2.0 Flash                                                    â”‚
â”‚      Provider: Google                                                       â”‚
â”‚      Input:    $0.10/1M tokens                                              â”‚
â”‚      Output:   $0.40/1M tokens                                              â”‚
â”‚      Context:  1M                                                           â”‚
â”‚      Score:    88/100                                                       â”‚
â”‚      Warum:    Noch gÃ¼nstiger, aber weniger konsistent                      â”‚
â”‚                                                                             â”‚
â”‚  ğŸ¥‰ #3: DeepSeek V3                                                         â”‚
â”‚      Provider: DeepSeek                                                     â”‚
â”‚      Input:    $0.27/1M tokens                                              â”‚
â”‚      Output:   $1.10/1M tokens                                              â”‚
â”‚      Context:  64K                                                          â”‚
â”‚      Score:    82/100                                                       â”‚
â”‚      Warum:    Sehr gÃ¼nstig, aber China-based (Compliance?)                 â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Integration mit init-project

Dieser Skill wird automatisch wÃ¤hrend `/init-project` aufgerufen:

1. User beschreibt Projekt (Step 0.1)
2. KomplexitÃ¤tsstufe wird ermittelt (Step 0.2)
3. **`/llm-evaluate` lÃ¤uft im Hintergrund**
4. Stack-Empfehlung inkl. LLM-Empfehlung (Step 0.3)

---

**Version:** 1.0
**Last Updated:** January 2026
